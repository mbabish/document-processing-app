version: '3.8'

services:
  backend:
    build:
      context: ..
      dockerfile: docker/Dockerfile.backend
    ports:
      - "5000:5000"
    volumes:
      - ../backend:/app
    environment:
      - FLASK_ENV=development
      - FLASK_APP=app.py
      - FLASK_DEBUG=1
      - PYTHONUNBUFFERED=1
    restart: unless-stopped

  frontend:
    build:
      context: ..
      dockerfile: docker/Dockerfile.frontend
    ports:
      - "3000:3000"
    volumes:
      - ../frontend:/app
      - /app/node_modules
    depends_on:
      - backend
    environment:
      - REACT_APP_API_URL=http://localhost:5000
      - CHOKIDAR_USEPOLLING=true
      - WATCHPACK_POLLING=true
      - WDS_SOCKET_PORT=3000
      - FAST_REFRESH=false
    stdin_open: true
    restart: unless-stopped

  llm:
    build:
      context: ..
      dockerfile: docker/Dockerfile.llm
    ports:
      - "8000:8000"
    volumes:
      - ../llm:/app
      - llm-cache:/root/.cache  # Persistent cache for model downloads
    environment:
      - LOG_LEVEL=INFO
    restart: unless-stopped
    # If your machine has limited memory, you might want to limit the container
    deploy:
      resources:
        limits:
          memory: 4G  # Adjust based on your system's available memory

volumes:
  llm-cache:  # Define a named volume for the model cache